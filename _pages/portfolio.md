---
layout: archive
title: ""
permalink: /portfolio/
author_profile: true
---


# Work Experience

<h2 style="margin-top: 30px; margin-bottom: 4px;">
  Graduate Research Assistant @ 
  <a href="https://rpm-lab.github.io">Robotics Perception and Manipulation Lab</a>
</h2>
<p style="margin-top: 0; margin-bottom: 8px;">
  <em>January 2024 – Present</em>
</p>

<p style="margin-top: 0; margin-bottom: 10px;">
  At the Robotics Perception and Manipulation Lab, I am working on advanced research in robot manipulation, with a focus on enabling robots to learn tasks from human demonstrations. My research aims to simplify the teaching process and enhance safety by allowing robots to quickly adapt to new tasks through observation. One of the key projects that I was involved in includes developing a system that observes a human disassembling an object and generates part-specific grasps for downstream manipulation.
</p>

<p style="margin-top: 0; margin-bottom: 20px;">
  Most recently, I have been leading the development of a grasp generation system that learns task-specific grasps on novel objects from a single video demonstration. This approach shifts from traditional geometry-based manipulation to a more flexible, goal-driven method, enabling robots to learn in a more human-like way.
</p>



<h2 style="margin-top: 0; margin-bottom: 4px;">
  Software Engineering Intern @ 
  <a href="https://www.nilfisk.com/global/">Nilfisk</a>
</h2>
<p style="margin-top: 0; margin-bottom: 8px;">
  <em>May 2023 – December 2023</em>
</p>

<p style="margin-top: 0; margin-bottom: 10px;">
  During my time here, I focused on developing perception systems for autonomous machines. My primary responsibility was to build object detection models for specific objects, but there were no readily available datasets for this task. To address this challenge, I explored synthetic data generation techniques and leveraged NVIDIA’s Isaac Sim to create tailored datasets for training.
</p>

<p style="margin-top: 0;">
  Using NVIDIA's Isaac Sim Replicator library, I developed virtual training environments that allowed YOLOv8 models to learn to detect objects in factory settings. Additionally, I built a custom annotation tool with the Segment Anything Model (SAM) to streamline data preparation for object segmentation tasks, significantly speeding up the data annotation process.
</p>

